# video-diffusion-papers
This seminar will focus on the latest developments in the field of diffusion models, particularly video diffusion models. Topics will include aspects such as temporal and identity consistency, efficiency, and applications specifically in the realm of human avatars.

Resources:
<br>
- [Diffusion models blogpost (more intuitive approach)](https://iclr-blogposts.github.io/2024/blog/diffusion-theory-from-scratch/)
- [Blog covering many subjects in Diffusion models - highly recommended](https://sander.ai/)
- [Tutorail on diffusion models (in-depth and detailed)](https://arxiv.org/pdf/2403.18103)
<br>
<br>

| Title | Paper / Resource | Year | Why is it interesting? |          Asignee          | Recording | Slides
|:---:|:---:|:---:|:---:|:-------------------------:|:---:|:---:|
|Introduction||| <details><summary>read why</summary>Review of key concepts from our previous seminar, followed by a brief overview the new seminar</details> |       Shira Bar On        |[zoom](link)(password)|[slides](link) |
|Video Diffusion Model in Latent Space|[Video Probabilistic Diffusion Models in Projected Latent Space](https://arxiv.org/abs/2302.07685)<br>+<br>[Align Your Latents](https://arxiv.org/abs/2304.08818)|2023| <details><summary>read why</summary>Example of two different approaches for Video Latent Diffusion Models</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|Denoising Diffusion Implicit Models (DDIM) and Distillation|[DDIM](https://arxiv.org/abs/2010.02502)<br>+<br>[Knowledge Distillation in Iterative Generative Models for Improved Sampling Speed](https://arxiv.org/abs/2101.02388)|2020, 2021| <details><summary>read why</summary>DDIM: paper introducing deterministic sampling, distillation paper lowers the number of sampling steps to one by building on this concept</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|Diffusion Transformer|[DiT](https://arxiv.org/abs/2212.09748)|2022| <details><summary>read why</summary>Replacing the Unet base of the diffusion model with Transformer base, which improves results and the condition control</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|AnimateDiff|[AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning](https://arxiv.org/abs/2307.04725)|ICLR'24 spotlight| <details><summary>read why</summary>Introducing the Idea of converting of-the shelf text-to-image diffusion model to text-to-video diffusion model</details> | [Ganit Kupershmidt](link) |[zoom](link)(password)|[slides](link) |
|Animate Anyone|[Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation](https://arxiv.org/abs/2311.17117)|2023| <details><summary>read why</summary>Video diffusion for avatar animation, introducing ReferenceNet for identity preservation</details> |   [Matan Feldman](link)   |[zoom](link)(password)|[slides](link) |
|Guest Speaker (Lightricks)|TBD|| <details><summary>read why</summary>TBD</details> |            TBD            |[zoom](link)(password)|[slides](link) |
|EMO: Emote Portrait Alive|[EMO](https://arxiv.org/abs/2402.17485)|2024| <details><summary>read why</summary>Face Animation using video diffusion models, using one image and audio as inputs</details> |    [Alon Mengi](link)     |[zoom](link)(password)|[slides](link) |
|Gen1 (Runway) |[Gen1](https://arxiv.org/abs/2302.03011), [gen2 blog](https://research.runwayml.com/gen2)|2023| <details><summary>read why</summary>Gen 1, 2, and 3 models are among the known video diffusion models</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|Advanced Topics in Distillation|[Progressive Distillation](https://arxiv.org/abs/2202.00512)<br>+<br>[Consistancy Models](https://arxiv.org/abs/2303.01469)|2022, 2023| <details><summary>read why</summary>two approaches for lowering the number of sampling steps</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|Rectified Flow |[Rectified Flow](https://openreview.net/pdf/910c5efa5739a5d2bef83d432da87d3096712ebe.pdf)<br>+<br>[InstaFlow](https://arxiv.org/abs/2309.06380)|2023| <details><summary>read why</summary>Rectified Flow optimizes diffusion models by straightening their transport paths, Instaflow applis this technique</details> |       [name](link)        |[zoom](link)(password)|[slides](link) |
|Generative Image Dynamics|[Generative Image Dynamics](https://arxiv.org/abs/2309.07906)|CVPR 2024 Best Paper Award| <details><summary>read why</summary>Using diffusion models to generate image dynamics, using the Fourier domain</details> |   [Roy Hachnochi](https://github.com/roy-hachnochi)   |[zoom](link)(password)|[slides](link) |

